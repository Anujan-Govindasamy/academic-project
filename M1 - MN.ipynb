{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL NET ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amoeba = 'DATASET/TRAIN/Amoeba'\n",
    "Euglena = 'DATASET/TRAIN/Euglena'\n",
    "Hydra = 'DATASET/TRAIN/Hydra'\n",
    "Paramecium = 'DATASET/TRAIN/Paramecium'\n",
    "Rod_bacteria = 'DATASET/TRAIN/Rod_bacteria'\n",
    "Spherical_bacteria = 'DATASET/TRAIN/Spherical_bacteria'\n",
    "Spiral_bacteria = 'DATASET/TRAIN/Spiral_bacteria'\n",
    "Yeast = 'DATASET/TRAIN/Yeast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(item_dir, n=6):\n",
    "    all_item_dir = os.listdir(item_dir)  # Get all items in the directory\n",
    "    item_files = [os.path.join(item_dir, file) for file in all_item_dir][:n]  # Get file paths for first n items\n",
    "    \n",
    "    plt.figure(figsize=(80, 40))  # Create a large figure for plotting images\n",
    "    for idx, img_path in enumerate(item_files):\n",
    "        plt.subplot(3, n, idx+1)  # Create subplots\n",
    "        img = plt.imread(img_path)  # Read image using matplotlib\n",
    "        plt.imshow(img, cmap='gray')  # Display image in grayscale\n",
    "        plt.axis('off')  # Turn off axis\n",
    "    \n",
    "    plt.tight_layout()  # Adjust subplot parameters to give specified padding\n",
    "\n",
    "def image_details_print(data,path):\n",
    "    print('======== Images in: ', path)  # Print section header\n",
    "    for key,values in data.items():\n",
    "        print(key,':\\t', values)  # Print key-value pairs for image details\n",
    "\n",
    "\n",
    "def images_details(path):\n",
    "    files=[f for f in glob.glob(path + \"**/*.*\", recursive=True)]  # Get list of all image files in directory and subdirectories\n",
    "    data={}  # Initialize dictionary to store image details\n",
    "    data['Images_count']=len(files)  # Count total number of images\n",
    "    data['Min_width']=10**100  # Initialize minimum width with a very large number\n",
    "    data['Max_width']=0  # Initialize maximum width with 0\n",
    "    data['Min_height']=10**100  # Initialize minimum height with a very large number\n",
    "    data['Max_height']=0  # Initialize maximum height with 0\n",
    "    \n",
    "    for f in files:\n",
    "        img=Image.open(f)  # Open image using PIL\n",
    "        width,height=img.size  # Get width and height of the image\n",
    "        data['Min_width']=min(width,data['Min_width'])  # Update minimum width\n",
    "        data['Max_width']=max(width, data['Max_width'])  # Update maximum width\n",
    "        data['Min_height']=min(height, data['Min_height'])  # Update minimum height\n",
    "        data['Max_height']=max(height, data['Max_height'])  # Update maximum height\n",
    "        \n",
    "    image_details_print(data,path)  # Print image details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR Amoeba:\")\n",
    "print(\"\")\n",
    "images_details(Amoeba)\n",
    "print(\"\")\n",
    "plot_images(Amoeba, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR Euglena:\")\n",
    "print(\"\")\n",
    "images_details(Euglena)\n",
    "print(\"\")\n",
    "plot_images(Euglena, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR Hydra:\")\n",
    "print(\"\")\n",
    "images_details(Hydra)\n",
    "print(\"\")\n",
    "plot_images(Hydra, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR Yeast:\")\n",
    "print(\"\")\n",
    "images_details(Yeast)\n",
    "print(\"\")\n",
    "plot_images(Yeast, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR Paramecium:\")\n",
    "print(\"\")\n",
    "images_details(Paramecium)\n",
    "print(\"\")\n",
    "plot_images(Paramecium, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR Rod_bacteria:\")\n",
    "print(\"\")\n",
    "images_details(Rod_bacteria)\n",
    "print(\"\")\n",
    "plot_images(Rod_bacteria, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale pixel values to [0,1] range\n",
    "    shear_range=0.2,  # Apply shear transformation\n",
    "    zoom_range=0.2,  # Apply zoom transformation\n",
    "    horizontal_flip=True  # Apply horizontal flip\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/train',  # Path to the training dataset directory\n",
    "    target_size=(224, 224),  # Resize images to 224x224\n",
    "    batch_size=32,  # Number of samples per gradient update\n",
    "    class_mode='categorical'  # Type of label array (categorical for one-hot encoded labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test',    # Path to the test dataset directory\n",
    "    target_size=(224, 224),  # Resize images to 224x224\n",
    "    batch_size=32,            # Number of samples per batch\n",
    "    class_mode='categorical'  # Type of label array (categorical for one-hot encoded labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a sequential model\n",
    "Classifier = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, each filter size is 3x3,\n",
    "# input images are expected to be of size 224x224 pixels with 3 channels (RGB),\n",
    "# and ReLU activation function is used\n",
    "Classifier.add(Convolution2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "\n",
    "# Add a max pooling layer with a pooling window size of 2x2\n",
    "Classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "Classifier.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer with 38 neurons and ReLU activation function\n",
    "Classifier.add(Dense(38, activation='relu'))\n",
    "\n",
    "# Add another fully connected layer with 8 neurons and softmax activation function\n",
    "# Softmax is used for multi-class classification to output probabilities for each class\n",
    "Classifier.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model with RMSprop optimizer, categorical crossentropy loss function,\n",
    "# and accuracy as the metric to track during training and testing\n",
    "Classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model save \n",
    "model_path = \"MANUAL.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='accuracy', verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fitting the model\n",
    "history = Classifier.fit(\n",
    "           training_set, steps_per_epoch=training_set.samples // batch_size, \n",
    "           epochs=epochs, \n",
    "           validation_data=test_set,validation_steps=test_set.samples // batch_size,\n",
    "           callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph():\n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph():\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
